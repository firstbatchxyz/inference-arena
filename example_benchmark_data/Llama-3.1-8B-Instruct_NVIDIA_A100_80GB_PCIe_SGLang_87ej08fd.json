{
  "model_name": "Llama-3.1-8B-Instruct",
  "benchmark_type": "throughput",
  "parameter_size": "8b",
  "inference_engine": "SGLang",
  "hardware": "NVIDIA A100 80GB PCIe",
  "memory": 300,
  "download_speed": null,
  "server_type": "Runpod",
  "cost": 0.19816666666666666,
  "avg_ttft_ms": 126.54846647511357,
  "avg_throughput": 651.2747737678155,
  "test_duration": 340.457824,
  "container_setup": 110,
  "avg_input_token_per_request": 89.97340425531915,
  "avg_output_token_per_request": 97.73369565217394,
  "total_requests": 188,
  "model_download_time": 110,
  "server_cost_per_hour": 1.64
}